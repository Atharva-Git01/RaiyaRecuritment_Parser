# Resume Parsing & Screening Platform â€” System Architecture Dissection

**Document Version:** 1.0  
**Date:** December 23, 2025  
**Audience:** New Interns & Technical Contributors  
**Classification:** Internal Technical Documentation

---

## Executive Summary

This document provides a **complete technical dissection** of the Resume Parsing & Screening Platformâ€”a production-grade, AI-powered recruitment automation system built for recruiters at Raiya Solutions.

**What This System Does:**
- Accepts bulk resume uploads (PDF format)
- Parses resumes using Azure OpenAI (Phi-4 model) into structured JSON
- Validates and normalizes extracted data with strict anti-hallucination rules
- Scores candidates against a Job Description (JD) using hybrid matching (deterministic + semantic + AI)
- Generates explainable reports with recruiter summaries, candidate feedback, and visual analytics
- Persists all data in a multi-tenant MySQL database
- Provides a real-time web dashboard for batch processing and results review

**Core Philosophy:**
1. **Zero Hallucination:** The system never invents skills, experience, or qualifications
2. **Explainability:** Every score is backed by matched/missing items and clear reasoning
3. **Recruiter Trust:** Scores are deterministic and reproducible; AI is used only for interpretation, not facts
4. **Single JD Per Batch:** Simplifies matching logic and prevents cross-JD confusion

---

## 1. System Architecture Overview

### 1.1 High-Level Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         FRONTEND (HTML/JS)                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ Bulk Upload  â”‚  â”‚  Processing  â”‚  â”‚   Results    â”‚          â”‚
â”‚  â”‚   Platform   â”‚  â”‚    Queue     â”‚  â”‚  Dashboard   â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BACKEND (FastAPI Server)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  server.py: HTTP API + Background Task Orchestration     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     PIPELINE ORCHESTRATOR                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  main.py: run_full_pipeline() â€” Single Resume Pipeline  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ Extract  â”‚ Normalizeâ”‚  Parse   â”‚ Validate â”‚  Score   â”‚       â”‚
â”‚  â”‚  (PDF)   â”‚  (Text)  â”‚  (AI)    â”‚ (Rules)  â”‚ (Hybrid) â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                              â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ AI Score â”‚  Explain â”‚  Report  â”‚ Persist  â”‚                  â”‚
â”‚  â”‚  (Phi-4) â”‚ (Engine) â”‚  (PDF)   â”‚  (DB)    â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   DATABASE (MySQL - SaaS Schema)                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ Tenants  â”‚   BUs    â”‚   JDs    â”‚ Batches  â”‚   Jobs   â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚           Resume Results (Parsed + Scores)           â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 Technology Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **Frontend** | HTML5, TailwindCSS, Vanilla JS, Chart.js | Real-time dashboard, bulk upload UI |
| **Backend** | FastAPI (Python), Uvicorn | REST API, background task orchestration |
| **AI/LLM** | Azure OpenAI (Phi-4 model) | Resume parsing, AI-assisted scoring |
| **NLP** | SentenceTransformers (all-MiniLM-L6-v2) | Semantic skill/tech matching |
| **Database** | MySQL 8.0 | Multi-tenant SaaS schema, job persistence |
| **PDF Processing** | PyMuPDF (fitz), pdfplumber | Text extraction from resumes |
| **Report Generation** | ReportLab | PDF report creation |

---

## 2. End-to-End Pipeline Flow (CRITICAL)

This is the **exact lifecycle** of a resume from upload to final report. Every intern must understand this flow.

### 2.1 Pipeline Stages

#### **Stage 0: Ingestion (User Action)**
- **File:** [server.py](file:///c:/Users/asr26/OneDrive/Desktop/Reaper/Work_101/RaiyaRecuritment_Parser/phi%204/server.py) â†’ `/api/upload` endpoint
- **Input:** PDF resumes + [job_description.json](file:///c:/Users/asr26/OneDrive/Desktop/Reaper/Work_101/RaiyaRecuritment_Parser/phi%204/job_description.json)
- **Output:** Files saved to `uploads/` directory
- **Why:** Prepares files for batch processing

#### **Stage 1: Batch Creation**
- **File:** [server.py](file:///c:/Users/asr26/OneDrive/Desktop/Reaper/Work_101/RaiyaRecuritment_Parser/phi%204/server.py) â†’ `/api/process` endpoint
- **Input:** All PDFs in `uploads/`
- **Output:** Database records created:
  - 1 Batch record (status: [processing](file:///c:/Users/asr26/OneDrive/Desktop/Reaper/Work_101/RaiyaRecuritment_Parser/phi%204/server.py#79-82))
  - 1 JD record (from [job_description.json](file:///c:/Users/asr26/OneDrive/Desktop/Reaper/Work_101/RaiyaRecuritment_Parser/phi%204/job_description.json))
  - N Job records (one per resume, status: `queued`)
- **Why:** Tracks processing state across distributed workers

#### **Stage 2: Background Worker Dispatch**
- **File:** [server.py](file:///c:/Users/asr26/OneDrive/Desktop/Reaper/Work_101/RaiyaRecuritment_Parser/phi%204/server.py) â†’ [process_single_resume()](file:///c:/Users/asr26/OneDrive/Desktop/Reaper/Work_101/RaiyaRecuritment_Parser/phi%204/server.py#222-309) (FastAPI BackgroundTasks)
- **Input:** Job ID, resume path, JD data, database IDs
- **Output:** Job status updated to `running`
- **Why:** Enables parallel processing without blocking API

#### **Stage 3: Text Extraction**
- **File:** [app/extractor.py](file:///c:/Users/asr26/OneDrive/Desktop/Reaper/Work_101/RaiyaRecuritment_Parser/phi%204/app/extractor.py) â†’ `extract_resume_text()`
- **Input:** PDF file path
- **Output:** Raw text string
- **Logic:**
  - Tries PyMuPDF first (fast, handles most PDFs)
  - Falls back to pdfplumber if PyMuPDF fails
  - Saves to `storage/tmp/{resume_name}__extracted.txt`
- **Why:** Converts binary PDF to machine-readable text

#### **Stage 4: Text Normalization**
- **File:** [app/normalizer.py](file:///c:/Users/asr26/OneDrive/Desktop/Reaper/Work_101/RaiyaRecuritment_Parser/phi%204/app/normalizer.py) â†’ `normalize_resume_text()`
- **Input:** Raw extracted text
- **Output:** Cleaned, structured markdown text
- **Logic:**
  - Removes headers/footers, page numbers, watermarks
  - Fixes encoding issues (UTF-8 normalization)
  - Standardizes bullet points, section headers
  - Saves to `storage/tmp/{resume_name}__normalized.md`
- **Why:** Improves LLM parsing accuracy by removing noise

#### **Stage 5: AI Parsing (Azure Phi-4)**
- **File:** [app/parser.py](file:///c:/Users/asr26/OneDrive/Desktop/Reaper/Work_101/RaiyaRecuritment_Parser/phi%204/app/parser.py) â†’ [parse_resume()](file:///c:/Users/asr26/OneDrive/Desktop/Reaper/Work_101/RaiyaRecuritment_Parser/phi%204/app/parser.py#219-250)
- **Input:** Normalized text
- **Output:** Structured JSON with fields:
  ```json
  {
    "name": "string",
    "email": "string",
    "phone": "string",
    "location": "string",
    "skills": ["string"],
    "education": [{"degree", "institution", "year"}],
    "experience": [{"company", "role", "start_date", "end_date", "description"}],
    "projects": [{"name", "description"}],
    "summary": "string",
    "certificates": [{"name", "issuer", "year"}],
    "salary": {"current_ctc_lpa", "expected_ctc_lpa"}
  }
  ```
- **Logic:**
  - Sends normalized text to Azure OpenAI API
  - Uses strict system prompt: **"Extract ONLY what is explicitly present. Do NOT infer, guess, or add synonyms."**
  - Retries with increased `max_tokens` if JSON parsing fails
  - Saves to `storage/tmp/{resume_name}__parsed.json`
- **Why:** Converts unstructured text to queryable data

#### **Stage 6: Validation**
- **File:** [app/validator.py](file:///c:/Users/asr26/OneDrive/Desktop/Reaper/Work_101/RaiyaRecuritment_Parser/phi%204/app/validator.py) â†’ [validate_resume_data()](file:///c:/Users/asr26/OneDrive/Desktop/Reaper/Work_101/RaiyaRecuritment_Parser/phi%204/app/validator.py#636-1129)
- **Input:** Parsed JSON
- **Output:** Validated + enriched JSON
- **Logic:**
  - **Date Normalization:** Converts all dates to `YYYY-MM` format
  - **Experience Calculation:** Computes total years from timeline (not LLM output)
  - **Salary Extraction:** Regex-based extraction from raw text (fallback if LLM missed it)
  - **Project Extraction:** Fallback extraction from raw text if LLM failed
  - **Course Extraction:** Extracts coursework from raw text
  - **Description Normalization:** Converts experience descriptions to list format
  - Saves to `storage/tmp/{resume_name}__validated.json`
- **Why:** Fixes LLM hallucinations and fills gaps with deterministic logic

#### **Stage 7: Pre-Scoring Normalization**
- **File:** [app/normalizer_pre_score.py](file:///c:/Users/asr26/OneDrive/Desktop/Reaper/Work_101/RaiyaRecuritment_Parser/phi%204/app/normalizer_pre_score.py) â†’ [normalize_for_scoring()](file:///c:/Users/asr26/OneDrive/Desktop/Reaper/Work_101/RaiyaRecuritment_Parser/phi%204/app/normalizer_pre_score.py#117-179)
- **Input:** Validated JSON
- **Output:** Scoring-ready JSON with normalized aliases
- **Logic:**
  - Maps skill aliases: `"react"` â†’ `"ReactJS"`, `"ml"` â†’ `"Machine Learning"`
  - Maps tech aliases: `"postgres"` â†’ `"PostgreSQL"`, `"aws"` â†’ `"AWS"`
  - Maps education aliases: `"btech"` â†’ `"Bachelor's Degree in Engineering"`
  - **CRITICAL:** Separates skill/tech aliases from education aliases to prevent degrees appearing as skills
  - Saves to `storage/tmp/{resume_name}__scoring_ready.json`
- **Why:** Ensures consistent vocabulary for matching

#### **Stage 8: Local Matcher Scoring**
- **File:** [app/matcher.py](file:///c:/Users/asr26/OneDrive/Desktop/Reaper/Work_101/RaiyaRecuritment_Parser/phi%204/app/matcher.py) â†’ [score_resume_against_jd()](file:///c:/Users/asr26/OneDrive/Desktop/Reaper/Work_101/RaiyaRecuritment_Parser/phi%204/app/matcher.py#456-784)
- **Input:** Scoring-ready JSON, JD JSON
- **Output:** Score object with 10 component scores + final score
- **Logic:**
  1. **Skills Matching (30% weight):**
     - Phase 1: Exact substring match with word boundaries (regex `\b`)
     - Phase 2: Semantic match using SentenceTransformers (threshold: 0.45)
     - Returns: `matched_list`, `missing_list`, `skills_score` (0-100)
  2. **Technologies Matching (5% weight):**
     - Same hybrid approach as skills
  3. **Tools Matching (5% weight):**
     - Same hybrid approach
  4. **Experience Scoring (25% weight):**
     - Calculates total years from timeline (ignores LLM-provided field)
     - **CRITICAL FILTER:** Semantically filters out irrelevant roles (e.g., "Finance Intern" for "Software Engineer" JD)
     - Compares against JD experience range
  5. **Relevant Experience Scoring (10% weight):**
     - Maps JD skills to years of experience per skill
     - Averages across all JD skills
     - Maps to JD criteria buckets (e.g., `">=5 years_relevant": 30`)
  6. **Projects Scoring (10% weight):**
     - Extracts keywords from JD projects
     - Matches keywords in resume projects
  7. **Certificates Scoring (5% weight):**
     - Exact + semantic match
  8. **Qualification Scoring (5% weight):**
     - Substring match on degree field
  9. **Responsibilities Scoring (3% weight):**
     - Semantic match on JD responsibilities
  10. **Salary Scoring (2% weight):**
      - Maps candidate salary to JD salary bands
  - **Final Score:** Weighted sum of all component scores
  - Saves to `storage/results/{resume_name}__local_score.json`
- **Why:** Provides deterministic, explainable baseline score

#### **Stage 9: AI Scorer (Azure Phi-4)**
- **File:** [app/ai_scorer.py](file:///c:/Users/asr26/OneDrive/Desktop/Reaper/Work_101/RaiyaRecuritment_Parser/phi%204/app/ai_scorer.py) â†’ [ai_score_resume()](file:///c:/Users/asr26/OneDrive/Desktop/Reaper/Work_101/RaiyaRecuritment_Parser/phi%204/app/ai_scorer.py#250-448)
- **Input:** Scoring-ready JSON, JD JSON, local scores (fallback)
- **Output:** AI score object (same schema as local score)
- **Logic:**
  - Sends resume + JD to Azure OpenAI with strict anti-hallucination prompt:
    - **"Experience MUST be calculated ONLY from job timelines, NOT from summary or top-level fields"**
    - **"IGNORE roles irrelevant to the job title (e.g., Finance for Software Engineer)"**
    - **"Skills MUST appear in experience.description or projects.description, NOT just in skills list"**
    - **"BEWARE OF CGPA: If you see 8.33, 9.5 as experience, it's a parsing errorâ€”IGNORE IT"**
  - Validates AI output schema
  - Recomputes `final_score` using weights if AI's score is inconsistent
  - **Hybrid Fallback:** If AI returns 0 but local matcher found matches, merges local data into AI result
  - Saves to `storage/results/{resume_name}__ai_score.json`
- **Why:** Provides nuanced scoring with synonym handling and context understanding

#### **Stage 10: Explanation Generation**
- **File:** [app/explanation_engine.py](file:///c:/Users/asr26/OneDrive/Desktop/Reaper/Work_101/RaiyaRecuritment_Parser/phi%204/app/explanation_engine.py) â†’ [generate_full_report()](file:///c:/Users/asr26/OneDrive/Desktop/Reaper/Work_101/RaiyaRecuritment_Parser/phi%204/app/explanation_engine.py#535-559)
- **Input:** Merged score object (local + AI)
- **Output:** Explanation JSON with:
  - `recruiter_text_summary`: 1-3 sentence factual summary
  - [candidate_feedback](file:///c:/Users/asr26/OneDrive/Desktop/Reaper/Work_101/RaiyaRecuritment_Parser/phi%204/app/explanation_engine.py#120-182): Actionable improvement tips
  - [structured_explanation](file:///c:/Users/asr26/OneDrive/Desktop/Reaper/Work_101/RaiyaRecuritment_Parser/phi%204/app/explanation_engine.py#191-306): JSON with strengths, gaps, matched/missing items
  - [visual_payload](file:///c:/Users/asr26/OneDrive/Desktop/Reaper/Work_101/RaiyaRecuritment_Parser/phi%204/app/explanation_engine.py#308-467): Chart data (radar, bar, gauge)
  - `ui_components`: Section metadata for frontend
- **Logic:**
  - Purely deterministic (no AI calls)
  - Generates text from score object using templates
  - Prioritizes gaps by weight (skills > projects > tools)
  - Saves to `storage/results/{resume_name}__explanation.json`
- **Why:** Makes scores human-readable for recruiters

#### **Stage 11: PDF Report Generation**
- **File:** [app/pdf_report.py](file:///c:/Users/asr26/OneDrive/Desktop/Reaper/Work_101/RaiyaRecuritment_Parser/phi%204/app/pdf_report.py) â†’ `generate_pdf_report()`
- **Input:** Explanation JSON
- **Output:** PDF file with visual report
- **Logic:**
  - Uses ReportLab to create multi-page PDF
  - Includes: candidate summary, score breakdown, matched/missing items, visual charts
  - Saves to `storage/reports/{resume_name}__report_{timestamp}.pdf`
- **Why:** Provides offline, shareable report for recruiters

#### **Stage 12: Database Persistence**
- **File:** [app/saas_db.py](file:///c:/Users/asr26/OneDrive/Desktop/Reaper/Work_101/RaiyaRecuritment_Parser/phi%204/app/saas_db.py) â†’ [save_resume_result()](file:///c:/Users/asr26/OneDrive/Desktop/Reaper/Work_101/RaiyaRecuritment_Parser/phi%204/app/saas_db.py#421-450)
- **Input:** Job ID, parsed JSON, scores JSON, report URL
- **Output:** Database record in [resume_results](file:///c:/Users/asr26/OneDrive/Desktop/Reaper/Work_101/RaiyaRecuritment_Parser/phi%204/app/saas_db.py#537-551) table
- **Logic:**
  - Inserts row with `job_id`, `parsed_resume_json`, `scores_json`, `report_url`, `processed_at`
  - Updates job status to `completed`
  - Checks if all jobs in batch are done â†’ updates batch status to `completed`
- **Why:** Enables historical tracking, analytics, and multi-user access

---

## 3. Backend Deep Dive

### 3.1 Module Responsibilities

| Module | Responsibility | Input | Output | Business Logic | Orchestration Logic |
|--------|---------------|-------|--------|----------------|---------------------|
| **main.py** | Pipeline orchestrator | Resume path, JD dict, job_id | Result dict | âŒ | âœ… (calls all modules sequentially) |
| **server.py** | HTTP API + background tasks | HTTP requests | JSON responses | âŒ | âœ… (dispatches workers, manages state) |
| **extractor.py** | PDF â†’ text | PDF path | Text string | âœ… (PDF parsing) | âŒ |
| **normalizer.py** | Text cleaning | Raw text | Cleaned text | âœ… (regex, encoding fixes) | âŒ |
| **parser.py** | Text â†’ JSON (AI) | Normalized text | Parsed JSON | âœ… (LLM prompt engineering) | âŒ |
| **validator.py** | JSON validation + enrichment | Parsed JSON | Validated JSON | âœ… (date parsing, salary extraction, fallback logic) | âŒ |
| **normalizer_pre_score.py** | Alias normalization | Validated JSON | Scoring-ready JSON | âœ… (alias mapping) | âŒ |
| **matcher.py** | Deterministic scoring | Resume JSON, JD JSON | Score object | âœ… (matching algorithms, semantic search) | âŒ |
| **ai_scorer.py** | AI-assisted scoring | Resume JSON, JD JSON | AI score object | âœ… (LLM prompt, validation) | âŒ |
| **explanation_engine.py** | Score â†’ human text | Score object | Explanation JSON | âœ… (text generation, chart data) | âŒ |
| **pdf_report.py** | JSON â†’ PDF | Explanation JSON | PDF file | âœ… (ReportLab rendering) | âŒ |
| **saas_db.py** | Database access layer | Job data | Database records | âœ… (SQL queries, connection pooling) | âŒ |

### 3.2 Job Queue & Worker Model

**Queue Implementation:**
- **In-Memory Queue:** `JOBS` dict in [server.py](file:///c:/Users/asr26/OneDrive/Desktop/Reaper/Work_101/RaiyaRecuritment_Parser/phi%204/server.py) (key: job_id, value: job state)
- **Database Queue:** [jobs](file:///c:/Users/asr26/OneDrive/Desktop/Reaper/Work_101/RaiyaRecuritment_Parser/phi%204/server.py#401-407) table in MySQL (persistent, survives restarts)
- **Worker Model:** FastAPI BackgroundTasks (thread pool, non-blocking)

**Job Lifecycle States:**
1. `queued` â†’ Job created, waiting for worker
2. `running` â†’ Worker picked up job, processing started
3. `completed` â†’ All stages finished successfully
4. `failed` â†’ Error occurred at any stage

**Status Tracking:**
- **In-Memory:** Real-time updates for frontend polling (`/api/jobs`)
- **Database:** Persistent state for historical tracking

**Idempotency:**
- Before processing, checks if `{resume_name}__explanation.json` exists
- If exists, loads from disk instead of re-processing
- Prevents duplicate work on server restart or retry

**Retry Logic:**
- No automatic retry (to prevent infinite loops on bad PDFs)
- Manual retry via "Retry Failed Jobs" button (not implemented yet)

**Failure Handling:**
- Errors logged to console
- Job status set to `failed`
- Error message stored in `JOBS[job_id]["error"]`
- Batch status set to `failed` if any job fails

### 3.3 Concurrency & Parallelism

- **Parallel Processing:** Multiple resumes processed concurrently via FastAPI BackgroundTasks
- **Thread Safety:** Each job operates on separate files (no shared state)
- **Database Pooling:** MySQL connection pool (size: 5) prevents connection exhaustion
- **Rate Limiting:** None (relies on Azure OpenAI quota limits)

---

## 4. Database Design & Role

### 4.1 Schema Overview (SaaS Multi-Tenant)

```sql
tenants
â”œâ”€â”€ tenant_id (PK)
â”œâ”€â”€ tenant_name
â”œâ”€â”€ status
â””â”€â”€ created_at

business_units
â”œâ”€â”€ bu_id (PK)
â”œâ”€â”€ tenant_id (FK â†’ tenants)
â”œâ”€â”€ bu_name
â””â”€â”€ created_at

job_descriptions
â”œâ”€â”€ jd_id (PK)
â”œâ”€â”€ bu_id (FK â†’ business_units)
â”œâ”€â”€ jd_title
â”œâ”€â”€ jd_data_json (TEXT)
â””â”€â”€ created_at

batches
â”œâ”€â”€ batch_id (PK)
â”œâ”€â”€ bu_id (FK â†’ business_units)
â”œâ”€â”€ uploader_user_id
â”œâ”€â”€ status (pending, processing, completed, failed)
â”œâ”€â”€ batch_guid (UUID)
â””â”€â”€ created_at

jobs
â”œâ”€â”€ job_id (PK)
â”œâ”€â”€ batch_id (FK â†’ batches)
â”œâ”€â”€ jd_id (FK â†’ job_descriptions)
â”œâ”€â”€ requester_user_id
â”œâ”€â”€ status (queued, running, completed, failed)
â””â”€â”€ created_at

resume_results
â”œâ”€â”€ result_id (PK)
â”œâ”€â”€ job_id (FK â†’ jobs)
â”œâ”€â”€ parsed_resume_json (TEXT)
â”œâ”€â”€ scores_json (TEXT)
â”œâ”€â”€ report_url
â””â”€â”€ processed_at
```

### 4.2 Data Flow

**Source of Truth:**
- **Parsed Resume:** `resume_results.parsed_resume_json` (validated JSON from Stage 6)
- **Scores:** `resume_results.scores_json` (merged local + AI scores)
- **JD:** `job_descriptions.jd_data_json`

**Derived Data:**
- **Explanation:** Generated on-the-fly from scores (not stored in DB, only in `storage/results/`)
- **PDF Report:** Generated on-the-fly, URL stored in `resume_results.report_url`

**State Persistence:**
- **Job Status:** Tracks pipeline progress (queued â†’ running â†’ completed/failed)
- **Batch Status:** Aggregated from job statuses (processing â†’ completed/failed)

### 4.3 Why Job-Based Model?

1. **Scalability:** Each resume is an independent job (can distribute across workers)
2. **Fault Tolerance:** Failed jobs don't block entire batch
3. **Auditability:** Every resume has a unique job_id with full history
4. **Multi-Tenancy:** Tenants/BUs isolate data for different organizations

---

## 5. AI Usage & Safety Rules (STRICT)

### 5.1 Where AI is Used

| Stage | AI Model | Purpose | Hallucination Risk | Mitigation |
|-------|----------|---------|-------------------|-----------|
| **Parsing** | Azure Phi-4 | Extract structured data from text | **HIGH** | Strict prompt + validation fallback |
| **AI Scoring** | Azure Phi-4 | Nuanced scoring with synonym handling | **MEDIUM** | Local score fallback + schema validation |

### 5.2 Where AI is NOT Allowed

- **Experience Calculation:** ALWAYS use timeline-based calculation, NEVER trust LLM output
- **Skill Matching:** ALWAYS verify skills appear in experience/projects, NOT just skills list
- **Salary Extraction:** ALWAYS use regex-based extraction from raw text
- **Date Parsing:** ALWAYS use deterministic date normalization
- **Final Scoring:** ALWAYS recompute using weights, NEVER trust AI's final_score directly

### 5.3 Anti-Hallucination Mechanisms

1. **Parser Prompt:**
   - "Extract ONLY information that is explicitly present"
   - "Do NOT infer, guess, assume, fabricate, extend, or add any missing content"
   - "Do not add synonyms (e.g., 'ML' â†’ 'Machine Learning')"
   - "If uncertain, leave the field empty"

2. **AI Scorer Prompt:**
   - "Experience MUST be calculated ONLY from job timelines"
   - "IGNORE roles irrelevant to the job title"
   - "Skills MUST appear in experience.description or projects.description"
   - "BEWARE OF CGPA: If you see 8.33, 9.5 as experience, it's a parsing error"

3. **Validator Fallbacks:**
   - If LLM misses salary â†’ regex extraction
   - If LLM misses projects â†’ raw text extraction
   - If LLM provides wrong experience â†’ timeline calculation overrides

4. **Matcher Filters:**
   - Semantic filtering of irrelevant job roles (similarity < 0.35 to JD job title)
   - Word boundary matching for skills (prevents "AI" matching "Raiya")

### 5.4 Deterministic vs AI-Assisted vs AI-Generated

| Data Type | Source | Trust Level | Example |
|-----------|--------|-------------|---------|
| **Deterministic** | Regex, timeline calculation, exact match | **100% (Ground Truth)** | Total experience years, salary extraction |
| **AI-Assisted** | LLM parsing + validation fallback | **80% (Verified)** | Skills list, education, projects |
| **AI-Generated** | LLM interpretation (not facts) | **50% (Explanatory Only)** | Recruiter summary, candidate feedback |

**Rule:** Never use AI-generated content as input to scoring. Only use for explanation.

---

## 6. Frontend & Recruiter UX

### 6.1 Recruiter Journey

```
1. Upload Resumes + JD
   â†“
2. Click "Start Processing"
   â†“
3. Monitor Queue (bulk-processing.html)
   - Real-time progress bars
   - Status updates (Queued â†’ In Progress â†’ Completed)
   - Score distribution chart
   â†“
4. View Results (recruiter-results.html)
   - Ranked candidate list (sorted by score)
   - Matched/missing skills
   - Experience coverage
   - Salary fit
   â†“
5. Download Reports
   - Individual PDF reports
   - Bulk CSV export
```

### 6.2 Frontend Pages

| Page | Purpose | Data Source | Update Frequency |
|------|---------|-------------|------------------|
| **recruiter-platform.html** | Bulk upload UI | Static | N/A |
| **bulk-processing.html** | Real-time queue monitoring | `/api/jobs` | 2 seconds (polling) |
| **recruiter-results.html** | Ranked candidate dashboard | `/api/results` | On load |
| **screening-results.html** | Individual candidate detail | `/api/results/{filename}` | On load |
| **history.html** | Batch history | `/api/batch-history` | On load |
| **settings.html** | User profile, API keys | `/api/settings` | On save |

### 6.3 Why UI Avoids Complexity

- **Recruiters are not data scientists:** Show summaries, not raw JSON
- **Decision speed matters:** Highlight top candidates, hide low scorers
- **Trust requires transparency:** Show matched/missing items, not just scores
- **Mobile-friendly:** Responsive design for on-the-go reviews

### 6.4 Frontend â†’ Backend Mapping

| UI Element | Backend Field | Calculation |
|------------|---------------|-------------|
| **Final Score** | `explanation.final_score` | Weighted sum of 10 component scores |
| **Matched Skills** | `matched_items.skills.matched` | Hybrid substring + semantic match |
| **Missing Skills** | `matched_items.skills.missing` | JD skills - matched skills |
| **Experience Years** | `details.candidate_total_experience_years` | Timeline calculation (ignores LLM) |
| **Salary Fit** | `matched_items.salary.matched_band` | Candidate salary vs JD bands |

---

## 7. Design Decisions & Tradeoffs

### 7.1 Why Only One JD Per Batch?

**Decision:** Each batch processes resumes against a single JD.

**Rationale:**
- Simplifies matching logic (no cross-JD comparison)
- Prevents recruiter confusion (clear context per batch)
- Reduces database complexity (no many-to-many JD-resume mapping)

**Tradeoff:** Cannot compare same resume against multiple JDs in one batch.

**Future Extension:** Multi-JD support would require:
- New table: `job_jd_mappings` (many-to-many)
- UI changes: JD selector per resume
- Scoring changes: Store scores per JD-resume pair

### 7.2 Why Experience is Weighted Highest?

**Decision:** Experience score has 25% weight (highest after skills at 30%).

**Rationale:**
- Recruiters prioritize years of experience over certifications
- Experience is harder to fake than skills list
- Timeline-based calculation is more reliable than LLM parsing

**Tradeoff:** Junior candidates with strong skills but low experience score lower.

**Mitigation:** Relevant experience score (10% weight) rewards skill-specific experience.

### 7.3 Why Salary is Optional / Late-Stage?

**Decision:** Salary score is only 2% weight, and missing salary doesn't fail the resume.

**Rationale:**
- Many candidates omit salary from resumes
- Salary negotiation happens after initial screening
- Prevents false negatives (good candidates filtered out due to missing salary)

**Tradeoff:** Cannot pre-filter by budget.

**Future Extension:** Add salary filter in UI (post-scoring).

### 7.4 Why Normalization Happens Before Scoring?

**Decision:** Separate normalization stage (`normalizer_pre_score.py`) before matching.

**Rationale:**
- Ensures consistent vocabulary (e.g., "React" vs "ReactJS")
- Reduces false negatives in matching
- Centralizes alias management (easier to update)

**Tradeoff:** Adds extra pipeline stage (minor latency).

**Alternative Rejected:** Inline normalization in matcher (harder to maintain, duplicates logic).

### 7.5 Why Explainability is Mandatory?

**Decision:** Every score includes matched/missing items and textual explanation.

**Rationale:**
- Builds recruiter trust (no "black box" scores)
- Enables candidate feedback (actionable improvement tips)
- Supports legal compliance (explainable hiring decisions)

**Tradeoff:** Larger JSON payloads (explanation objects are verbose).

**Mitigation:** Store explanations in files, not database (only URL in DB).

---

## 8. Known Limitations & Guardrails

### 8.1 What Interns Must NOT Change Without Approval

| Component | Why It's Critical | Risk if Changed |
|-----------|------------------|-----------------|
| **Weights in `matcher.py`** | Aligned with recruiter expectations | Scores become incomparable across batches |
| **Anti-hallucination prompts** | Prevents skill/experience fabrication | Trust breakdown, legal issues |
| **Timeline-based experience calculation** | Ground truth for experience | Hallucinated experience scores |
| **Word boundary regex in matcher** | Prevents false matches (e.g., "AI" in "Raiya") | Inflated scores, recruiter complaints |
| **Database schema** | Multi-tenant isolation | Data leaks, GDPR violations |

### 8.2 System Assumptions

1. **Single JD per batch** (no multi-JD comparison)
2. **PDF resumes only** (no DOCX, images, etc.)
3. **English language only** (no i18n support)
4. **Azure OpenAI availability** (no offline mode)
5. **MySQL database** (no NoSQL support)
6. **Synchronous pipeline** (no async/await in main.py)

### 8.3 What Would Break Recruiter Trust?

- Changing weights without notice (scores become incomparable)
- Removing matched/missing items (loses transparency)
- Allowing AI to invent skills (hallucination)
- Ignoring timeline for experience (trusting LLM over facts)
- Mixing scores from different JD versions (inconsistent criteria)

### 8.4 Future Extensions (Not Implemented)

- **Multi-JD Comparison:** Score same resume against multiple JDs
- **Resume Deduplication:** Detect and merge duplicate candidates
- **Candidate Ranking Algorithms:** ML-based ranking beyond weighted scores
- **Interview Scheduling Integration:** Auto-schedule top candidates
- **Email Notifications:** Notify recruiters when batch completes
- **Advanced Analytics:** Cohort analysis, hiring funnel metrics
- **DOCX Support:** Parse Word documents
- **OCR Support:** Extract text from scanned PDFs
- **Multi-Language Support:** i18n for non-English resumes

---

## 9. Mental Model: How to Think About This System

### 9.1 Core Principles

1. **Pipeline, Not Monolith:** Each stage is independent and testable
2. **Deterministic First, AI Second:** Use AI only where deterministic logic fails
3. **Explainability Over Accuracy:** A 70% score with clear reasoning beats an 80% black box
4. **Recruiter-Centric:** Every feature serves recruiter decision-making
5. **Zero Hallucination:** Never invent data; if unsure, leave blank

### 9.2 When Adding Features

**Ask Yourself:**
1. Does this help recruiters make faster/better decisions?
2. Can I explain this feature to a non-technical recruiter?
3. Does this introduce hallucination risk?
4. Will this break existing scores (backward compatibility)?
5. Is this deterministic or AI-assisted?

**Example: Adding a new skill to JD**
- âœ… **Good:** Add to `job_description.json` â†’ matcher picks it up automatically
- âŒ **Bad:** Hardcode skill in matcher.py â†’ breaks for other JDs

### 9.3 Debugging Checklist

**If scores are wrong:**
1. Check `storage/tmp/{resume_name}__parsed.json` â†’ Did LLM extract correctly?
2. Check `storage/tmp/{resume_name}__validated.json` â†’ Did validator fix errors?
3. Check `storage/tmp/{resume_name}__scoring_ready.json` â†’ Are aliases normalized?
4. Check `storage/results/{resume_name}__local_score.json` â†’ What did matcher find?
5. Check `storage/results/{resume_name}__ai_score.json` â†’ Did AI override local?
6. Check `storage/results/{resume_name}__explanation.json` â†’ What's the final merged score?

**If pipeline fails:**
1. Check `resume_analysis.log` â†’ What stage failed?
2. Check `storage/errors/` â†’ Any raw LLM outputs saved?
3. Check database `jobs` table â†’ What's the job status?
4. Check in-memory `JOBS` dict â†’ What's the error message?

### 9.4 Safe Areas to Modify

| Area | Safety Level | Examples |
|------|--------------|----------|
| **Frontend UI** | ğŸŸ¢ Safe | Colors, layout, chart types |
| **Explanation templates** | ğŸŸ¢ Safe | Wording of recruiter summaries |
| **Alias mappings** | ğŸŸ¡ Moderate | Adding new skill aliases (test thoroughly) |
| **Weights** | ğŸ”´ Dangerous | Requires recruiter approval + re-scoring all batches |
| **Prompts** | ğŸ”´ Dangerous | Changes affect all future parses (A/B test first) |
| **Database schema** | ğŸ”´ Dangerous | Requires migration + backward compatibility |

---

## 10. Quick Reference

### 10.1 File Locations

| Data Type | Location | Format |
|-----------|----------|--------|
| **Uploaded Resumes** | `uploads/*.pdf` | PDF |
| **Job Description** | `uploads/job_description.json` | JSON |
| **Extracted Text** | `storage/tmp/*__extracted.txt` | Text |
| **Normalized Text** | `storage/tmp/*__normalized.md` | Markdown |
| **Parsed JSON** | `storage/tmp/*__parsed.json` | JSON |
| **Validated JSON** | `storage/tmp/*__validated.json` | JSON |
| **Scoring-Ready JSON** | `storage/tmp/*__scoring_ready.json` | JSON |
| **Local Scores** | `storage/results/*__local_score.json` | JSON |
| **AI Scores** | `storage/results/*__ai_score.json` | JSON |
| **Explanations** | `storage/results/*__explanation.json` | JSON |
| **PDF Reports** | `storage/reports/*__report_{timestamp}.pdf` | PDF |

### 10.2 API Endpoints

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/api/upload` | POST | Upload resumes + JD |
| `/api/process` | POST | Start batch processing |
| `/api/jobs` | GET | Get real-time job statuses |
| `/api/results` | GET | Get all processed results |
| `/api/results/{filename}` | GET | Get single result |
| `/api/batch-history` | GET | Get batch history |
| `/api/settings` | GET/POST | User settings |

### 10.3 Environment Variables

| Variable | Purpose | Example |
|----------|---------|---------|
| `AZURE_OPENAI_ENDPOINT` | Azure OpenAI API URL | `https://your-resource.openai.azure.com` |
| `AZURE_OPENAI_DEPLOYMENT` | Model deployment name | `phi-4` |
| `AZURE_OPENAI_API_KEY` | API key | `abc123...` |
| `DB_HOST` | MySQL host | `localhost` |
| `DB_PORT` | MySQL port | `3306` |
| `DB_USER` | MySQL user | `root` |
| `DB_PASSWORD` | MySQL password | `password` |
| `DB_NAME` | Database name | `saas_db` |

### 10.4 Key Metrics

| Metric | Calculation | Interpretation |
|--------|-------------|----------------|
| **Final Score** | Weighted sum of 10 components | 0-100 (higher = better fit) |
| **Skills Match %** | (Matched skills / JD skills) Ã— 100 | Coverage of required skills |
| **Experience Fit %** | (Candidate years / JD min years) Ã— 100 | Experience adequacy |
| **Batch Completion %** | (Completed jobs / Total jobs) Ã— 100 | Processing progress |

---

## Conclusion

This system is designed for **recruiter trust, explainability, and zero hallucination**. Every design decision prioritizes these principles over raw accuracy or speed.

**As an intern, your role is to:**
1. **Understand the pipeline flow** (Section 2)
2. **Respect the anti-hallucination rules** (Section 5)
3. **Test changes thoroughly** (Section 9.3)
4. **Ask before modifying critical components** (Section 8.1)

**Remember:** This system processes real hiring decisions. A bug here affects people's careers. Code carefully, test rigorously, and always ask if unsure.

---

**Document Maintainer:** Senior Systems Architect  
**Last Updated:** December 23, 2025  
**Next Review:** Quarterly or on major system changes
