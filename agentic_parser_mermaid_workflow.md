# Intelligent Resume Transformation Agent â€” Mermaid Workflow Diagrams

## Powered by LangGraph & Azure OpenAI Phi-4 LLM

---

## 1. Complete End-to-End Pipeline Workflow

```mermaid
flowchart TD
    %% â”€â”€ Styles â”€â”€
    classDef startEnd fill:#1A73E8,stroke:#0D47A1,color:#fff,stroke-width:2px,font-weight:bold
    classDef initPhase fill:#E3F2FD,stroke:#1565C0,color:#0D47A1,stroke-width:1.5px
    classDef parseAgent fill:#E8F5E9,stroke:#2E7D32,color:#1B5E20,stroke-width:1.5px
    classDef universalExt fill:#C8E6C9,stroke:#388E3C,color:#1B5E20,stroke-width:1.5px
    classDef reasonAgent fill:#FFF3E0,stroke:#E65100,color:#BF360C,stroke-width:1.5px
    classDef deterministicNode fill:#C8E6C9,stroke:#2E7D32,color:#1B5E20,stroke-width:1.5px
    classDef llmNode fill:#FFCDD2,stroke:#C62828,color:#B71C1C,stroke-width:1.5px
    classDef optLlmNode fill:#FFF9C4,stroke:#F9A825,color:#E65100,stroke-width:1.5px
    classDef validateAgent fill:#F3E5F5,stroke:#6A1B9A,color:#4A148C,stroke-width:1.5px
    classDef hitlAgent fill:#E0F2F1,stroke:#00695C,color:#004D40,stroke-width:1.5px
    classDef storeAgent fill:#FCE4EC,stroke:#AD1457,color:#880E4F,stroke-width:1.5px
    classDef errorStyle fill:#FFCDD2,stroke:#C62828,color:#B71C1C,stroke-width:2px
    classDef decisionStyle fill:#FFF3E0,stroke:#E65100,color:#BF360C,stroke-width:1.5px
    classDef adapterStyle fill:#FFE0B2,stroke:#EF6C00,color:#BF360C,stroke-width:1.5px
    classDef validatorStyle fill:#E8EAF6,stroke:#283593,color:#1A237E,stroke-width:1.5px
    classDef resultStyle fill:#F1F8E9,stroke:#558B2F,color:#33691E,stroke-width:1.5px

    %% â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    %%  START
    %% â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    START(["ğŸš€ START â€” Resume File Input<br/>(PDF / DOCX / TXT / RTF)"]):::startEnd

    %% â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    %%  PHASE 0: INITIALIZATION
    %% â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    START --> INIT

    subgraph INIT_PHASE["Phase 0: Initialization"]
        direction TB
        INIT["âš™ï¸ Load .env Variables<br/>â”€â”€ AZURE_OPENAI_API_KEY<br/>â”€â”€ AZURE_OPENAI_ENDPOINT<br/>â”€â”€ AZURE_OPENAI_API_VERSION<br/>â”€â”€ AZURE_OPENAI_DEPLOYMENT_NAME = phi-4"]:::initPhase
        INIT --> CLIENT["ğŸ”Œ Initialize AzureOpenAI Client<br/>(temperature=0, strict JSON mode)"]:::initPhase
        CLIENT --> GRAPH_BUILD["ğŸ”— Create LangGraph StateGraph<br/>Compile: parse â†’ reasoning_extract â†’<br/>validate_enrich â†’ human_review â†’ store â†’ END"]:::initPhase
    end

    %% â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    %%  PHASE 1: STATE SCHEMA
    %% â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    GRAPH_BUILD --> STATE_DEF

    subgraph STATE_PHASE["Phase 1: State Schema Definition"]
        STATE_DEF["ğŸ“‹ Define ResumeState TypedDict<br/>â”€â”€ file_path, file_type<br/>â”€â”€ raw_text, parse_error<br/>â”€â”€ extraction_metadata<br/>â”€â”€ structured_data, extract_error<br/>â”€â”€ validated_data, validation_error<br/>â”€â”€ human_approved, human_review_notes<br/>â”€â”€ database_id, store_error<br/>â”€â”€ status, messages list"]:::initPhase
    end

    %% â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    %%  PHASE 2: PARSE AGENT
    %% â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    STATE_DEF --> PARSE_START

    subgraph PARSE_PHASE["Phase 2: Parse Agent â€” Compulsory Delegate to UniversalExtractor"]
        direction TB
        PARSE_START["ğŸ” parse_agent(state)<br/>LangGraph Node<br/>Reads: state.file_path"]:::parseAgent

        PARSE_START --> SYSPATH["ğŸ“‚ Add extraction pipeline to sys.path<br/>modularized_resume_extraction_normalization/"]:::parseAgent

        SYSPATH --> INIT_UE["ğŸ—ï¸ Initialize UniversalExtractor<br/>UniversalExtractor(use_gpu=False,<br/>use_neural_ocr=False)"]:::parseAgent

        %% â”€â”€ UniversalExtractor Internal â”€â”€
        INIT_UE --> UE_CALL

        subgraph UE_BOX["UniversalExtractor.extract_universal(file_path)"]
            direction TB
            UE_CALL["ğŸ” Step 0: File Identity Hash<br/>SHA-256 of raw file bytes"]:::universalExt
            UE_CALL --> LAYOUT["ğŸ” Step 1: LayoutDetector.detect_multi_layout()<br/>â”€â”€ Page count analysis<br/>â”€â”€ Column/sidebar pattern detection<br/>â”€â”€ Image vs text classification"]:::universalExt

            LAYOUT --> LAYOUT_DEC{"Multi-page AND<br/>multi-layout?<br/>(sidebar / multi-column)"}:::decisionStyle

            LAYOUT_DEC -->|"YES"| MULTI["ğŸ“ _extract_multi_layout_custom()<br/>â”€â”€ ColumnExtractor per page<br/>â”€â”€ _classify_content_sides()<br/>â”€â”€ _extract_candidate_name()"]:::universalExt
            LAYOUT_DEC -->|"NO"| STD["ğŸ“„ StandardExtractor.extract()<br/>â”€â”€ docstrange DocumentExtractor<br/>(single-page any layout OR<br/>multi-page single-column)"]:::universalExt

            MULTI --> FINGERPRINT
            STD --> FINGERPRINT

            FINGERPRINT["ğŸ” Step 3: Fingerprinting<br/>â”€â”€ content_hash = SHA-256(raw_text)<br/>â”€â”€ section_hashes = per-section SHA-256"]:::universalExt
            FINGERPRINT --> EXT_RESULT["ğŸ“¦ ExtractionResult<br/>â”€â”€ .content / .main_content / .sidebar_content<br/>â”€â”€ .layout_type, .pages, .is_image_based<br/>â”€â”€ .file_hash, .content_hash, .section_hashes<br/>â”€â”€ .get_raw_extracted_text() â†’ plain text<br/>â”€â”€ .to_enhanced_markdown() â†’ formatted md"]:::resultStyle
        end

        EXT_RESULT --> PARSE_CHECK{"raw_text is<br/>empty or None?"}:::decisionStyle
        PARSE_CHECK -->|"YES"| PARSE_ERR["âŒ ValueError<br/>state.parse_error = error<br/>state.raw_text = None"]:::errorStyle
        PARSE_CHECK -->|"NO"| PARSE_OK["âœ… Populate State<br/>state.raw_text = get_raw_extracted_text()<br/>state.parse_error = None<br/>state.extraction_metadata = {<br/>  layout_type, pages, is_image_based,<br/>  extraction_method, word_count,<br/>  file_hash, content_hash,<br/>  section_hashes, enhanced_markdown<br/>}"]:::resultStyle
    end

    %% â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    %%  PHASE 3: REASONING EXTRACT AGENT
    %% â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    PARSE_OK --> REASON_START
    PARSE_ERR --> REASON_START

    subgraph REASON_PHASE["Phase 3: Reasoning Extract Agent â€” Multi-Node Reasoning Graph"]
        direction TB
        REASON_START["ğŸ§  reasoning_extract_agent(state)<br/>LangGraph Node<br/>Source: pipeline_bridge.py"]:::reasonAgent

        REASON_START --> REASON_ERR_CHECK{"parse_error<br/>exists?"}:::decisionStyle
        REASON_ERR_CHECK -->|"YES"| REASON_SKIP["âŒ Set extract_error<br/>Cannot extract: parse failed<br/>Return state"]:::errorStyle

        REASON_ERR_CHECK -->|"NO"| ADAPTER_IN

        %% â”€â”€ Adapter In â”€â”€
        subgraph ADAPTER_IN_BOX["Extraction Adapter (In) â€” extraction_adapter.py"]
            ADAPTER_IN["ğŸ”„ extraction_result_to_reasoning_state()<br/>â”€â”€ split_sections() â€” regex-based<br/>â”€â”€ extract_roles_deterministic() â€” patterns<br/>â”€â”€ extract_skills_deterministic() â€” delimiters<br/>â”€â”€ Contact parsing â€” regex (email, phone, LinkedIn)"]:::adapterStyle
            ADAPTER_IN --> RSTATE["ğŸ“‹ ReasoningState Initialized<br/>â”€â”€ content_hash, raw_text<br/>â”€â”€ sections, roles, skills<br/>â”€â”€ audit_log: empty list"]:::adapterStyle
        end

        %% â”€â”€ 6-Node Sub-Graph â”€â”€
        RSTATE --> N1

        subgraph SUBGRAPH_BOX["6-Node Reasoning Sub-Graph â€” graph_runner.py"]
            direction TB
            N1["ğŸ”’ Node 1: section_authority_node<br/>âŒ No LLM â€” DETERMINISTIC<br/>â”€â”€ Validate experience claims â†” sections<br/>â”€â”€ Append authority_flag to roles<br/>â”€â”€ Audit: log section authority decisions"]:::deterministicNode

            N1 --> TIMELINE_CHECK{"Roles have<br/>date info?"}:::decisionStyle
            TIMELINE_CHECK -->|"YES"| N2["â±ï¸ Node 2: timeline_reasoner_node<br/>âŒ No LLM â€” DETERMINISTIC (Date Math)<br/>â”€â”€ Compute overlapping roles<br/>â”€â”€ Calculate total_months<br/>â”€â”€ Detect parallel employment inflation<br/>â”€â”€ Identify gaps between roles<br/>â”€â”€ Write: state.timeline_analysis"]:::deterministicNode
            TIMELINE_CHECK -->|"NO â€” skip"| N3

            N2 --> N3

            N3["ğŸ”— Node 3: skill_evidence_node<br/>âš ï¸ DETERMINISTIC + Optional LLM<br/>â”€â”€ Map skills â†’ role descriptions<br/>â”€â”€ Identify skill-without-usage<br/>â”€â”€ Optional LLM for ambiguous mappings<br/>â”€â”€ Write: state.normalized_skills"]:::optLlmNode

            N3 --> N4["ğŸ” Node 4: ambiguity_detector_node<br/>âœ… LLM CLASSIFICATION â€” Azure OpenAI Phi-4<br/>â”€â”€ Send pre-extracted phrases to LLM<br/>â”€â”€ Detect: worked on, familiar with,<br/>   knowledge of, exposure to<br/>â”€â”€ Prompt: ambiguity_prompt.txt (<200 tokens)<br/>â”€â”€ Write: state.ambiguities list"]:::llmNode

            N4 --> N5["ğŸ·ï¸ Node 5: classification_node<br/>âœ… LLM CLASSIFICATION â€” Azure OpenAI Phi-4<br/>â”€â”€ Send skills + context to LLM<br/>â”€â”€ Tag: professional / academic /<br/>   cert-only / tool-only<br/>â”€â”€ Prompt: classification_prompt.txt (<200 tokens)<br/>â”€â”€ Write: state.confidence_flags"]:::llmNode

            N5 --> N6["ğŸ” Node 6: finalization_node<br/>âŒ No LLM â€” DETERMINISTIC<br/>â”€â”€ Lock state (no further mutations)<br/>â”€â”€ Append complete audit trail entry<br/>â”€â”€ Return finalized ReasoningState"]:::deterministicNode
        end

        %% â”€â”€ Validators â”€â”€
        N6 --> VALIDATORS

        subgraph VALIDATOR_BOX["Validators â€” run after every node"]
            VALIDATORS["ğŸ›¡ï¸ schema_validator.py â€” enforce schema<br/>ğŸ•µï¸ hallucination_detector.py â€” flag invented data<br/>ğŸ” consistency_checker.py â€” cross-validate"]:::validatorStyle
        end

        %% â”€â”€ Adapter Out â”€â”€
        VALIDATORS --> ADAPTER_OUT

        subgraph ADAPTER_OUT_BOX["Extraction Adapter (Out) â€” extraction_adapter.py"]
            ADAPTER_OUT["ğŸ”„ reasoning_state_to_structured_data()<br/>â”€â”€ Map ReasoningState â†’ structured_data format<br/>â”€â”€ Include timeline_analysis, ambiguities,<br/>   confidence_flags, audit_log<br/>â”€â”€ Compatible with validate_and_enrich_agent"]:::adapterStyle
        end

        ADAPTER_OUT --> REASON_OK["âœ… state.structured_data = {<br/>  contact, summary, experience[],<br/>  education[], skills[], certifications[],<br/>  timeline_analysis, ambiguities,<br/>  confidence_flags, audit_log<br/>}<br/>state.extract_error = None"]:::resultStyle
    end

    %% â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    %%  PHASE 4: VALIDATE & ENRICH AGENT
    %% â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    REASON_OK --> VAL_START
    REASON_SKIP --> VAL_START

    subgraph VALIDATE_PHASE["Phase 4: Validate & Enrich Agent â€” Deterministic Python"]
        direction TB
        VAL_START["âœ¨ validate_and_enrich_agent(state)<br/>LangGraph Node<br/>Reads: state.structured_data"]:::validateAgent

        VAL_START --> VAL_ERR_CHECK{"extract_error<br/>exists?"}:::decisionStyle
        VAL_ERR_CHECK -->|"YES"| VAL_SKIP["âŒ Set validation_error<br/>Cannot validate: extraction failed"]:::errorStyle

        VAL_ERR_CHECK -->|"NO"| CLEAN["ğŸ§¹ 1. clean_contact_info(contact)<br/>â”€â”€ Validate email (must contain @)<br/>â”€â”€ Clean phone (strip non-numeric)<br/>â”€â”€ Strip whitespace"]:::validateAgent

        CLEAN --> CALC_EXP["ğŸ“… 2. calculate_experience(experience_list)<br/>â”€â”€ parse_date() for start/end dates<br/>â”€â”€ Sum months across positions<br/>â”€â”€ Convert â†’ years (1 decimal)<br/>â”€â”€ Present â†’ datetime.now()"]:::validateAgent

        CALC_EXP --> STD_SKILLS["ğŸ”§ 3. standardize_skills(skills)<br/>â”€â”€ Lowercase lookup â†’ STANDARD_SKILLS taxonomy<br/>â”€â”€ Deduplicate (reactjs + react â†’ React)<br/>â”€â”€ Sort alphabetically"]:::validateAgent

        STD_SKILLS --> ADD_META["ğŸ“ 4. Add Metadata<br/>â”€â”€ processed_date = ISO-8601<br/>â”€â”€ data_version = 1.0"]:::validateAgent

        ADD_META --> VAL_OK["âœ… state.validated_data = enriched JSON<br/>state.validation_error = None"]:::resultStyle
    end

    %% â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    %%  PHASE 5: HUMAN REVIEW (HITL)
    %% â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    VAL_OK --> HITL_START
    VAL_SKIP --> HITL_START

    subgraph HITL_PHASE["Phase 5: Human Review Agent â€” Visual Grounding (HITL)"]
        direction TB
        HITL_START["ğŸ‘ï¸ human_review_agent(state)<br/>LangGraph Node<br/>Reads: state.validated_data, state.file_path"]:::hitlAgent

        HITL_START --> HITL_ERR_CHECK{"validation_error<br/>exists?"}:::decisionStyle
        HITL_ERR_CHECK -->|"YES"| HITL_SKIP["âš ï¸ Skip review<br/>state.human_approved = False"]:::errorStyle

        HITL_ERR_CHECK -->|"NO"| GEN_IMG["ğŸ–¼ï¸ 1. Generate Resume Image<br/>pdf2image â†’ base64 PNG"]:::hitlAgent

        GEN_IMG --> BUILD_HTML["ğŸŒ 2. Build HTML Review Interface<br/>â”€â”€ Left panel: Resume image (zoomable)<br/>â”€â”€ Right panel: Editable fields<br/>   (contact, skills, experience, education)"]:::hitlAgent

        BUILD_HTML --> WRITE_HTML["ğŸ“‚ 3. Write HTML to temp file"]:::hitlAgent
        WRITE_HTML --> OPEN_BROWSER["ğŸŒ 4. Open in Browser<br/>webbrowser.open(html_file)"]:::hitlAgent
        OPEN_BROWSER --> WAIT_INPUT["â³ 5. Wait for Reviewer Decision<br/>Console input: approve / reject"]:::hitlAgent

        WAIT_INPUT --> HITL_DEC{"Reviewer<br/>Decision?"}:::decisionStyle
        HITL_DEC -->|"âœ… APPROVED"| HITL_APPROVE["âœ… Merge Edits into validated_data<br/>state.human_approved = True<br/>state.human_review_notes = notes"]:::resultStyle
        HITL_DEC -->|"âŒ REJECTED"| HITL_REJECT["âŒ Record Rejection<br/>state.human_approved = False<br/>state.human_review_notes = reason"]:::errorStyle
    end

    %% â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    %%  PHASE 6: STORE AGENT
    %% â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    HITL_APPROVE --> STORE_START
    HITL_REJECT --> STORE_START
    HITL_SKIP --> STORE_START

    subgraph STORE_PHASE["Phase 6: Store Agent â€” SQLite Database"]
        direction TB
        STORE_START["ğŸ’¾ store_agent(state)<br/>LangGraph Node<br/>Reads: state.validated_data, state.human_approved"]:::storeAgent

        STORE_START --> STORE_VAL_CHECK{"validation_error<br/>exists?"}:::decisionStyle
        STORE_VAL_CHECK -->|"YES"| STORE_FAIL["âŒ store_error<br/>status = failed"]:::errorStyle

        STORE_VAL_CHECK -->|"NO"| STORE_APPROVE_CHECK{"human_approved<br/>== False?"}:::decisionStyle
        STORE_APPROVE_CHECK -->|"YES â€” rejected"| STORE_REJECTED["âš ï¸ Skip Storage<br/>status = rejected"]:::errorStyle

        STORE_APPROVE_CHECK -->|"NO â€” approved"| INIT_DB["ğŸ—„ï¸ initialize_database()<br/>CREATE TABLE IF NOT EXISTS:<br/>â”€â”€ candidates (PK: id)<br/>â”€â”€ experience (FK: candidate_id)<br/>â”€â”€ education (FK: candidate_id)<br/>â”€â”€ skills (FK: candidate_id)<br/>â”€â”€ certifications (FK: candidate_id)"]:::storeAgent

        INIT_DB --> INSERT_DATA["ğŸ’¿ INSERT Records<br/>â”€â”€ candidates â†’ candidate_id<br/>â”€â”€ experience Ã— N entries<br/>â”€â”€ education Ã— N entries<br/>â”€â”€ skills Ã— N entries<br/>â”€â”€ certifications Ã— N entries"]:::storeAgent

        INSERT_DATA --> STORE_OK["âœ… state.database_id = candidate_id<br/>state.status = completed"]:::resultStyle
    end

    %% â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    %%  PHASE 7-9: RESULTS
    %% â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    STORE_OK --> SUMMARY
    STORE_FAIL --> SUMMARY
    STORE_REJECTED --> SUMMARY

    subgraph SUMMARY_PHASE["Phase 7â€“9: Results Summary & Query"]
        SUMMARY["ğŸ“Š Workflow Summary<br/>â”€â”€ Print all messages<br/>â”€â”€ Final Status: COMPLETED / REJECTED / FAILED<br/>â”€â”€ Database ID (if stored)<br/>â”€â”€ Human Review: âœ“ APPROVED / âœ— REJECTED"]:::initPhase
        SUMMARY --> QUERY["ğŸ” query_database()<br/>SELECT from candidates<br/>ORDER BY created_at DESC"]:::initPhase
    end

    QUERY --> FINISH(["ğŸ END"]):::startEnd
```

---

## 2. Reasoning Sub-Graph Internal Flow (Detailed)

```mermaid
flowchart TD
    classDef inputOutput fill:#E3F2FD,stroke:#1565C0,color:#0D47A1,stroke-width:2px
    classDef adapter fill:#FFE0B2,stroke:#EF6C00,color:#BF360C,stroke-width:1.5px
    classDef determ fill:#C8E6C9,stroke:#2E7D32,color:#1B5E20,stroke-width:1.5px
    classDef llm fill:#FFCDD2,stroke:#C62828,color:#B71C1C,stroke-width:1.5px
    classDef optLlm fill:#FFF9C4,stroke:#F9A825,color:#E65100,stroke-width:1.5px
    classDef validator fill:#E8EAF6,stroke:#283593,color:#1A237E,stroke-width:1.5px
    classDef decision fill:#FFF3E0,stroke:#E65100,color:#BF360C,stroke-width:1.5px

    IN(["ğŸ“¥ Input from Parse Agent<br/>raw_text + content_hash<br/>(via pipeline_bridge.py)"]):::inputOutput

    IN --> AIN

    subgraph ADAPTER_IN["Extraction Adapter In â€” extraction_adapter.py"]
        AIN["ğŸ”„ extraction_result_to_reasoning_state()<br/>â”€â”€ split_sections() â€” regex<br/>â”€â”€ extract_roles_deterministic() â€” patterns<br/>â”€â”€ extract_skills_deterministic() â€” delimiters<br/>â”€â”€ Contact parsing â€” regex"]:::adapter
        AIN --> RSINIT["ğŸ“‹ ReasoningState Initialized<br/>content_hash Â· raw_text Â· sections<br/>roles Â· skills Â· audit_log: empty"]:::adapter
    end

    RSINIT --> NODE1

    subgraph SUBGRAPH["6-Node LangGraph Sub-Graph â€” graph_runner.py"]
        direction TB
        NODE1["ğŸ”’ Node 1: section_authority_node<br/>âŒ DETERMINISTIC â€” No LLM<br/>â€¢ Validate experience claims â†” correct sections<br/>â€¢ Flag claims in wrong sections<br/>â€¢ Append authority_flag to each role<br/>â€¢ Audit: log section authority decisions"]:::determ

        NODE1 --> TC{"Roles have<br/>date info?"}:::decision

        TC -->|"YES"| NODE2["â±ï¸ Node 2: timeline_reasoner_node<br/>âŒ DETERMINISTIC â€” Pure Date Math<br/>â€¢ Compute overlapping roles<br/>â€¢ Calculate total_months<br/>â€¢ Detect parallel employment inflation<br/>â€¢ Identify gaps between roles<br/>â€¢ Write timeline_analysis"]:::determ

        TC -->|"NO â€” skip"| NODE3

        NODE2 --> NODE3

        NODE3["ğŸ”— Node 3: skill_evidence_node<br/>âš ï¸ DETERMINISTIC + Optional LLM<br/>â€¢ Map each skill â†’ role descriptions<br/>â€¢ Identify skill-without-usage<br/>â€¢ Optional LLM for ambiguous mappings<br/>â€¢ Write normalized_skills with evidence"]:::optLlm

        NODE3 --> NODE4["ğŸ” Node 4: ambiguity_detector_node<br/>âœ… LLM CLASSIFICATION<br/>Azure OpenAI Phi-4 (temp=0, JSON)<br/>â€¢ Send pre-extracted phrases to LLM<br/>â€¢ Detect vague/non-committal language<br/>â€¢ Prompt: ambiguity_prompt.txt < 200 tokens<br/>â€¢ Write ambiguities list"]:::llm

        NODE4 --> NODE5["ğŸ·ï¸ Node 5: classification_node<br/>âœ… LLM CLASSIFICATION<br/>Azure OpenAI Phi-4 (temp=0, JSON)<br/>â€¢ Send skills + context to LLM<br/>â€¢ Tag: professional / academic /<br/>  cert-only / tool-only<br/>â€¢ Prompt: classification_prompt.txt < 200 tokens<br/>â€¢ Write confidence_flags"]:::llm

        NODE5 --> NODE6["ğŸ” Node 6: finalization_node<br/>âŒ DETERMINISTIC â€” No LLM<br/>â€¢ Lock state â€” prevent further mutation<br/>â€¢ Append complete audit trail entry<br/>â€¢ Return finalized ReasoningState"]:::determ
    end

    NODE6 --> VALBOX

    subgraph VALIDATORS["Validators â€” run after every node"]
        VALBOX["ğŸ›¡ï¸ schema_validator.py<br/>No unknown keys Â· required fields Â· type checks<br/><br/>ğŸ•µï¸ hallucination_detector.py<br/>Skills/roles not in raw_text â†’ flagged or removed<br/><br/>ğŸ” consistency_checker.py<br/>Experience years vs timeline Â· skills vs roles"]:::validator
    end

    VALBOX --> AOUT

    subgraph ADAPTER_OUT["Extraction Adapter Out â€” extraction_adapter.py"]
        AOUT["ğŸ”„ reasoning_state_to_structured_data()<br/>â”€â”€ ReasoningState â†’ structured_data<br/>â”€â”€ Include reasoning metadata<br/>â”€â”€ Compatible with validate_and_enrich_agent"]:::adapter
    end

    AOUT --> OUT(["ğŸ“¤ Output â†’ state.structured_data<br/>{contact, summary, experience[],<br/>education[], skills[], certifications[],<br/>timeline_analysis, ambiguities,<br/>confidence_flags, audit_log}"]):::inputOutput
```

---

## 3. Error Propagation Flow

```mermaid
flowchart TD
    classDef ok fill:#C8E6C9,stroke:#2E7D32,color:#1B5E20,stroke-width:1.5px
    classDef err fill:#FFCDD2,stroke:#C62828,color:#B71C1C,stroke-width:1.5px
    classDef decision fill:#FFF3E0,stroke:#E65100,color:#BF360C,stroke-width:1.5px
    classDef agent fill:#E3F2FD,stroke:#1565C0,color:#0D47A1,stroke-width:1.5px,font-weight:bold
    classDef status fill:#F3E5F5,stroke:#6A1B9A,color:#4A148C,stroke-width:2px,font-weight:bold

    A1["ğŸ” Parse Agent"]:::agent
    A1 --> D1{"File read /<br/>extraction fails?"}:::decision
    D1 -->|"ERROR"| E1["âŒ state.parse_error = error"]:::err
    D1 -->|"OK"| O1["âœ… state.raw_text populated"]:::ok

    E1 --> A2
    O1 --> A2

    A2["ğŸ§  Reasoning Extract Agent"]:::agent
    A2 --> D2{"parse_error<br/>exists?"}:::decision
    D2 -->|"YES"| E2["âŒ state.extract_error =<br/>Cannot extract: parse failed<br/>Return immediately"]:::err
    D2 -->|"NO"| D2B{"Sub-graph node<br/>fails?"}:::decision
    D2B -->|"ERROR"| E2B["âŒ state.extract_error = error<br/>audit_log records failed node"]:::err
    D2B -->|"OK"| O2["âœ… state.structured_data populated"]:::ok

    E2 --> A3
    E2B --> A3
    O2 --> A3

    A3["âœ¨ Validate & Enrich Agent"]:::agent
    A3 --> D3{"extract_error<br/>exists?"}:::decision
    D3 -->|"YES"| E3["âŒ state.validation_error =<br/>Cannot validate: extraction failed"]:::err
    D3 -->|"NO"| D3B{"Data processing<br/>fails?"}:::decision
    D3B -->|"ERROR"| E3B["âŒ state.validation_error = error"]:::err
    D3B -->|"OK"| O3["âœ… state.validated_data populated"]:::ok

    E3 --> A4
    E3B --> A4
    O3 --> A4

    A4["ğŸ‘ï¸ Human Review Agent â€” HITL"]:::agent
    A4 --> D4{"validation_error<br/>exists?"}:::decision
    D4 -->|"YES"| E4["âš ï¸ state.human_approved = False<br/>Skip review"]:::err
    D4 -->|"NO"| O4["ğŸ‘ï¸ HTML Review Interface<br/>Approve or Reject"]:::ok

    E4 --> A5
    O4 --> A5

    A5["ğŸ’¾ Store Agent"]:::agent
    A5 --> D5{"validation_error<br/>exists?"}:::decision
    D5 -->|"YES"| S_FAIL["âŒ state.store_error<br/>state.status = FAILED"]:::status
    D5 -->|"NO"| D5B{"human_approved<br/>== False?"}:::decision
    D5B -->|"REJECTED"| S_REJECT["âš ï¸ state.status = REJECTED<br/>Skip storage"]:::status
    D5B -->|"APPROVED"| D5C{"SQLite insert<br/>fails?"}:::decision
    D5C -->|"ERROR"| S_FAIL2["âŒ state.store_error<br/>state.status = FAILED"]:::status
    D5C -->|"OK"| S_OK["âœ… state.database_id = candidate_id<br/>state.status = COMPLETED"]:::status
```

---

## 4. Cross-Pipeline Integration

```mermaid
flowchart LR
    classDef pipeline1 fill:#E3F2FD,stroke:#1565C0,color:#0D47A1,stroke-width:2px
    classDef pipeline2 fill:#FFF3E0,stroke:#E65100,color:#BF360C,stroke-width:2px
    classDef component fill:#FFFFFF,stroke:#1565C0,color:#0D47A1,stroke-width:1px
    classDef dbStyle fill:#FFF9C4,stroke:#F9A825,color:#E65100,stroke-width:2px
    classDef cloudStyle fill:#FFCDD2,stroke:#C62828,color:#B71C1C,stroke-width:2px

    subgraph P1["Pipeline 1: modularized_resume_extraction_normalization<br/>(Deterministic Extraction â€” Docstrange + Layout Detection)"]
        direction TB
        FILE["ğŸ“„ Resume File<br/>(PDF/DOCX/TXT/RTF)"]:::component
        UE["ğŸ—ï¸ UniversalExtractor<br/>(universal_extractor.py)"]:::component
        LD["ğŸ” LayoutDetector<br/>(layout_detector.py)"]:::component
        CE["ğŸ“ ColumnExtractor<br/>(column_extractor.py)"]:::component
        SE["ğŸ“„ StandardExtractor<br/>(standard_extraction.py)"]:::component
        HF["ğŸ“ HeadingFormatter<br/>(heading_formatter.py)"]:::component
        HA["ğŸ” Hashing<br/>(hashing.py)"]:::component
        ER["ğŸ“¦ ExtractionResult<br/>(extraction_models.py)"]:::component

        FILE --> UE
        UE --> LD
        LD -->|"multi-layout"| CE
        LD -->|"standard"| SE
        CE --> HF
        SE --> HF
        HF --> HA
        HA --> ER
    end

    subgraph P2["Pipeline 2: modularized_resume_parsing_agent<br/>(LangGraph + Azure OpenAI Phi-4)"]
        direction TB
        PA["ğŸ” Parse Agent<br/>(Compulsory Delegate)"]:::component
        RA["ğŸ§  Reasoning Extract<br/>(6-Node Sub-Graph)"]:::component

        subgraph NODES["Reasoning Nodes"]
            direction TB
            RN1["section_authority âŒ"]:::component
            RN2["timeline_reasoner âŒ"]:::component
            RN3["skill_evidence âš ï¸"]:::component
            RN4["ambiguity_detector âœ…"]:::component
            RN5["classification âœ…"]:::component
            RN6["finalization âŒ"]:::component
            RN1 --> RN2 --> RN3 --> RN4 --> RN5 --> RN6
        end

        VA["âœ¨ Validate & Enrich<br/>(Deterministic Python)"]:::component
        HR["ğŸ‘ï¸ Human Review â€” HITL<br/>(HTML Interface)"]:::component
        SA["ğŸ’¾ Store Agent<br/>(SQLite)"]:::component

        PA --> RA
        RA --> NODES
        RN6 --> VA
        VA --> HR
        HR --> SA
    end

    LLM["â˜ï¸ Azure OpenAI<br/>Phi-4 Model<br/>(classification only)"]:::cloudStyle

    DB[("ğŸ—„ï¸ resume_ats.db<br/>SQLite<br/>â”€â”€ candidates<br/>â”€â”€ experience<br/>â”€â”€ education<br/>â”€â”€ skills<br/>â”€â”€ certifications")]:::dbStyle

    ER -->|"get_raw_extracted_text()<br/>content_hash"| PA
    RN4 -.->|"classification call<br/>< 200 tokens"| LLM
    RN5 -.->|"classification call<br/>< 200 tokens"| LLM
    SA -->|"INSERT INTO<br/>5 normalised tables"| DB
```

---

## 5. Database Schema (Entity Relationship)

```mermaid
erDiagram
    candidates {
        INTEGER id PK "AUTOINCREMENT"
        TEXT name "NOT NULL"
        TEXT email
        TEXT phone
        TEXT location
        TEXT linkedin
        TEXT github
        TEXT summary
        REAL total_years_experience
        TEXT processed_date
        TEXT data_version
        BOOLEAN human_approved
        TEXT human_review_notes
        TIMESTAMP created_at "DEFAULT CURRENT_TIMESTAMP"
    }

    experience {
        INTEGER id PK "AUTOINCREMENT"
        INTEGER candidate_id FK
        TEXT company
        TEXT title
        TEXT start_date
        TEXT end_date
        TEXT description
    }

    education {
        INTEGER id PK "AUTOINCREMENT"
        INTEGER candidate_id FK
        TEXT institution
        TEXT degree
        TEXT field
        TEXT graduation_year
    }

    skills {
        INTEGER id PK "AUTOINCREMENT"
        INTEGER candidate_id FK
        TEXT skill
    }

    certifications {
        INTEGER id PK "AUTOINCREMENT"
        INTEGER candidate_id FK
        TEXT certification
    }

    candidates ||--o{ experience : "has"
    candidates ||--o{ education : "has"
    candidates ||--o{ skills : "has"
    candidates ||--o{ certifications : "has"
```

---

## 6. High-Level Workflow (Simplified State Diagram)

```mermaid
stateDiagram-v2
    [*] --> ParseAgent

    state "ğŸ” Parse Agent<br/>(Compulsory Delegate: UniversalExtractor)" as ParseAgent
    state "ğŸ§  Reasoning Extract Agent<br/>(6-Node Sub-Graph)" as ReasoningExtract
    state "âœ¨ Validate & Enrich<br/>(Deterministic Python)" as ValidateEnrich
    state "ğŸ‘ï¸ Human Review â€” HITL<br/>(HTML Visual Grounding)" as HumanReview
    state "ğŸ’¾ Store Agent<br/>(SQLite â€” 5 tables)" as StoreAgent

    state ReasoningExtract {
        [*] --> section_authority
        section_authority --> timeline_reasoner : deterministic
        timeline_reasoner --> skill_evidence : deterministic
        skill_evidence --> ambiguity_detector : determ + opt LLM
        ambiguity_detector --> classification : LLM classification
        classification --> finalization : LLM classification
        finalization --> [*] : deterministic
    }

    ParseAgent --> ReasoningExtract : raw_text + extraction_metadata
    ReasoningExtract --> ValidateEnrich : structured_data (JSON)
    ValidateEnrich --> HumanReview : validated_data (enriched JSON)
    HumanReview --> StoreAgent : human_approved + edits
    StoreAgent --> [*] : database_id + status
```

---

## 7. Parse Agent â€” UniversalExtractor Delegation Detail

```mermaid
flowchart TD
    classDef parseStyle fill:#E8F5E9,stroke:#2E7D32,color:#1B5E20,stroke-width:1.5px
    classDef ueStyle fill:#C8E6C9,stroke:#388E3C,color:#1B5E20,stroke-width:1.5px
    classDef decision fill:#FFF3E0,stroke:#E65100,color:#BF360C,stroke-width:1.5px
    classDef result fill:#F1F8E9,stroke:#558B2F,color:#33691E,stroke-width:1.5px
    classDef error fill:#FFCDD2,stroke:#C62828,color:#B71C1C,stroke-width:1.5px

    INPUT["ğŸ“„ state.file_path<br/>(PDF / DOCX / TXT)"]:::parseStyle
    INPUT --> DELEGATE["ğŸ—ï¸ UniversalExtractor.extract_universal(file_path)<br/>Source: modularized_resume_extraction_normalization/<br/>modules/extraction/universal_extractor.py"]:::ueStyle

    DELEGATE --> HASH["ğŸ” SHA-256 File Hash<br/>(raw file bytes)"]:::ueStyle
    HASH --> DETECT["ğŸ” LayoutDetector.detect_multi_layout()<br/>â”œâ”€â”€ Page count<br/>â”œâ”€â”€ Column/sidebar detection<br/>â””â”€â”€ Image vs text classification"]:::ueStyle

    DETECT --> DEC{"Multi-page AND<br/>sidebar/multi-column?"}:::decision

    DEC -->|"YES"| MULTI["ğŸ“ _extract_multi_layout_custom()<br/>â”œâ”€â”€ ColumnExtractor per page<br/>â”œâ”€â”€ _classify_content_sides() â€” main vs sidebar<br/>â””â”€â”€ _extract_candidate_name()"]:::ueStyle

    DEC -->|"NO"| STANDARD["ğŸ“„ StandardExtractor.extract()<br/>â””â”€â”€ docstrange DocumentExtractor"]:::ueStyle

    MULTI --> FPRINT["ğŸ” Fingerprinting<br/>â”œâ”€â”€ content_hash = SHA-256(text)<br/>â””â”€â”€ section_hashes = per-section SHA-256"]:::ueStyle
    STANDARD --> FPRINT

    FPRINT --> EXTRESULT["ğŸ“¦ ExtractionResult<br/>â”œâ”€â”€ .content / .main_content / .sidebar_content<br/>â”œâ”€â”€ .layout_type Â· .pages Â· .is_image_based<br/>â”œâ”€â”€ .file_hash Â· .content_hash Â· .section_hashes<br/>â”œâ”€â”€ .get_raw_extracted_text() â†’ plain text<br/>â””â”€â”€ .to_enhanced_markdown() â†’ formatted md"]:::result

    EXTRESULT --> CHECK{"raw_text<br/>empty?"}:::decision
    CHECK -->|"YES"| ERR["âŒ ValueError â€” Empty text<br/>state.parse_error = error"]:::error
    CHECK -->|"NO"| OK["âœ… state.raw_text = plain text<br/>state.extraction_metadata = {<br/>  layout_type, pages, is_image_based,<br/>  extraction_method, word_count,<br/>  file_hash, content_hash,<br/>  section_hashes, enhanced_markdown<br/>}"]:::result
```

---

## 8. HITL Human Review Decision Flow

```mermaid
flowchart TD
    classDef hitl fill:#E0F2F1,stroke:#00695C,color:#004D40,stroke-width:1.5px
    classDef decision fill:#FFF3E0,stroke:#E65100,color:#BF360C,stroke-width:1.5px
    classDef approve fill:#C8E6C9,stroke:#2E7D32,color:#1B5E20,stroke-width:2px
    classDef reject fill:#FFCDD2,stroke:#C62828,color:#B71C1C,stroke-width:2px
    classDef skip fill:#FFE0B2,stroke:#EF6C00,color:#BF360C,stroke-width:1.5px

    START["ğŸ‘ï¸ human_review_agent(state)<br/>Reads: validated_data + file_path"]:::hitl

    START --> VCHECK{"validation_error<br/>exists?"}:::decision
    VCHECK -->|"YES"| SKIP["âš ï¸ Skip review<br/>human_approved = False"]:::skip

    VCHECK -->|"NO"| IMG["ğŸ–¼ï¸ Convert resume page â†’ base64 PNG<br/>(pdf2image)"]:::hitl
    IMG --> HTML["ğŸŒ Build HTML Review Interface<br/>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”<br/>â”‚ ğŸ“„ Resume   â”‚ ğŸ“ Editable  â”‚<br/>â”‚ Image       â”‚ Fields       â”‚<br/>â”‚ (zoomable)  â”‚ Contact      â”‚<br/>â”‚             â”‚ Skills       â”‚<br/>â”‚             â”‚ Experience   â”‚<br/>â”‚             â”‚ Education    â”‚<br/>â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"]:::hitl
    HTML --> TEMP["ğŸ“‚ Write HTML â†’ temp file"]:::hitl
    TEMP --> BROWSER["ğŸŒ webbrowser.open(html_file)"]:::hitl
    BROWSER --> WAIT["â³ Wait for console input<br/>approve / reject"]:::hitl

    WAIT --> DEC{"Reviewer<br/>Decision?"}:::decision
    DEC -->|"âœ… APPROVED"| APPROVED["âœ… Merge edits into validated_data<br/>human_approved = True<br/>human_review_notes = reviewer notes"]:::approve
    DEC -->|"âŒ REJECTED"| REJECTED["âŒ Record rejection<br/>human_approved = False<br/>human_review_notes = reason"]:::reject

    APPROVED --> NEXT["â†’ Store Agent"]:::hitl
    REJECTED --> NEXT
    SKIP --> NEXT
```

---

## 9. Store Agent Decision Flow

```mermaid
flowchart TD
    classDef store fill:#FCE4EC,stroke:#AD1457,color:#880E4F,stroke-width:1.5px
    classDef decision fill:#FFF3E0,stroke:#E65100,color:#BF360C,stroke-width:1.5px
    classDef ok fill:#C8E6C9,stroke:#2E7D32,color:#1B5E20,stroke-width:2px
    classDef fail fill:#FFCDD2,stroke:#C62828,color:#B71C1C,stroke-width:2px
    classDef rejected fill:#FFE0B2,stroke:#EF6C00,color:#BF360C,stroke-width:1.5px
    classDef db fill:#FFF9C4,stroke:#F9A825,color:#E65100,stroke-width:2px

    START["ğŸ’¾ store_agent(state)<br/>Reads: validated_data, human_approved"]:::store

    START --> D1{"validation_error<br/>exists?"}:::decision
    D1 -->|"YES"| FAIL1["âŒ store_error<br/>status = FAILED"]:::fail

    D1 -->|"NO"| D2{"human_approved<br/>== False?"}:::decision
    D2 -->|"YES"| REJECT["âš ï¸ Skip Storage<br/>status = REJECTED"]:::rejected

    D2 -->|"NO"| INITDB["ğŸ—„ï¸ initialize_database()<br/>CREATE TABLE IF NOT EXISTS Ã— 5"]:::store
    INITDB --> INSERT

    subgraph INSERT_OPS["SQLite INSERT Operations"]
        INSERT["INSERT INTO candidates â†’ candidate_id"]:::db
        INSERT --> EXP["INSERT INTO experience Ã— N"]:::db
        EXP --> EDU["INSERT INTO education Ã— N"]:::db
        EDU --> SKL["INSERT INTO skills Ã— N"]:::db
        SKL --> CRT["INSERT INTO certifications Ã— N"]:::db
    end

    CRT --> D3{"SQLite insert<br/>success?"}:::decision
    D3 -->|"YES"| OK["âœ… database_id = candidate_id<br/>status = COMPLETED"]:::ok
    D3 -->|"ERROR"| FAIL2["âŒ store_error<br/>status = FAILED"]:::fail
```

---

> **How to Render:** Paste any of the Mermaid code blocks into:
> - [Mermaid Live Editor](https://mermaid.live/)
> - GitHub / GitLab markdown (native support)
> - VS Code with the **Markdown Preview Mermaid Support** extension
> - Any Mermaid-compatible documentation tool (Notion, Confluence, Docusaurus, etc.)
